======================================================================
MNIST 2NN Federated Learning Experiment
======================================================================
Start Time: 2025-11-02 19:40:15
Model: 2NN (199,210 parameters)

Configuration:
  Client Fraction (C): 1.0
  Local Epochs (E): 1
  Batch Size (B): 10
  Learning Rate: 0.01
  Data Partitioning: IID
  Max Rounds: 75
======================================================================


======================================================================
STRATEGY CONFIGURATION
======================================================================
Sampling:
  â”œâ”€â”€ Fraction: train (1.00) | evaluate (1.00)
  â”œâ”€â”€ Minimum nodes: train (2) | evaluate (2)
  â””â”€â”€ Minimum available nodes: 2

Keys in records:
  â”œâ”€â”€ Weighted by: 'num-examples'
  â”œâ”€â”€ ArrayRecord key: 'arrays'
  â””â”€â”€ ConfigRecord key: 'config'
======================================================================


======================================================================
STRATEGY CONFIGURATION
======================================================================
Sampling:
  â”œâ”€â”€ Fraction: train (1.00) | evaluate (1.00)
  â”œâ”€â”€ Minimum nodes: train (2) | evaluate (2)
  â””â”€â”€ Minimum available nodes: 2

Keys in records:
  â”œâ”€â”€ Weighted by: 'num-examples'
  â”œâ”€â”€ ArrayRecord key: 'arrays'
  â””â”€â”€ ConfigRecord key: 'config'
======================================================================

[Round 1] Configure Train: Sampled 100 nodes (out of 100)

[Round 1] Aggregate Train:
  â”œâ”€â”€ Received 99 results and 1 failures
  â”œâ”€â”€ Error from node 7213094353901836949: <class 'ray.exceptions.RayTaskError(ClientAppException)'>:<'[36mray::ClientAppActor.run()[39m (pid=134984, ip=127.0.0.1, actor_id=b7eeab642151a456c61cda4001000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x0000026D546DF2C0>)
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpcore\_sync\connection.py", line 103, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpcore\_sync\http11.py", line 136, in handle_request
    raise exc
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpcore\_sync\http11.py", line 106, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpcore\_sync\http11.py", line 177, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpcore\_backends\sync.py", line 126, in read
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LEGION\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=134984, ip=127.0.0.1, actor_id=b7eeab642151a456c61cda4001000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x0000026D546DF2C0>)
  File "D:\Research\FL_experiments\venv\Lib\site-packages\flwr\simulation\ray_transport\ray_actor.py", line 58, in run
    out_message = app(message=message, context=context)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\flwr\client\client_app.py", line 161, in __call__
    return self._registered_funcs[full_name](message, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\objectcounting\objectcounting\client_app.py", line 34, in train
    trainloader, _ = load_data(partition_id, num_partitions, iid=iid, batch_size=batch_size)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\objectcounting\objectcounting\Task_2NN.py", line 94, in load_data
    partition = fds.load_partition(partition_id)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\flwr_datasets\federated_dataset.py", line 177, in load_partition
    self._prepare_dataset()
  File "D:\Research\FL_experiments\venv\Lib\site-packages\flwr_datasets\federated_dataset.py", line 314, in _prepare_dataset
    self._dataset = datasets.load_dataset(
                    ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\datasets\load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\datasets\load.py", line 1890, in load_dataset_builder
    builder_instance: DatasetBuilder = builder_cls(
                                       ^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\datasets\builder.py", line 342, in __init__
    self.config, self.config_id = self._create_builder_config(
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\datasets\builder.py", line 597, in _create_builder_config
    builder_config._resolve_data_files(
  File "D:\Research\FL_experiments\venv\Lib\site-packages\datasets\builder.py", line 206, in _resolve_data_files
    self.data_files = self.data_files.resolve(base_path, download_config)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\datasets\data_files.py", line 818, in resolve
    out[key] = data_files_patterns_list.resolve(base_path, download_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\datasets\data_files.py", line 781, in resolve
    origin_metadata = _get_origin_metadata(data_files, download_config=download_config)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\datasets\data_files.py", line 548, in _get_origin_metadata
    return thread_map(
           ^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\tqdm\contrib\concurrent.py", line 69, in thread_map
    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\tqdm\contrib\concurrent.py", line 51, in _executor_map
    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\tqdm\std.py", line 1169, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "C:\Users\LEGION\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LEGION\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LEGION\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LEGION\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\LEGION\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\datasets\data_files.py", line 527, in _get_single_origin_metadata
    resolved_path = fs.resolve_path(data_file)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\huggingface_hub\hf_file_system.py", line 200, in resolve_path
    repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\huggingface_hub\hf_file_system.py", line 127, in _repo_and_revision_exist
    self._api.repo_info(
  File "D:\Research\FL_experiments\venv\Lib\site-packages\huggingface_hub\utils\_validators.py", line 89, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\huggingface_hub\hf_api.py", line 2756, in repo_info
    return method(
           ^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\huggingface_hub\utils\_validators.py", line 89, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\huggingface_hub\hf_api.py", line 2619, in dataset_info
    r = get_session().get(path, headers=headers, timeout=timeout, params=params)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpx\_client.py", line 1053, in get
    return self.request(
           ^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpx\_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LEGION\AppData\Local\Programs\Python\Python312\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "D:\Research\FL_experiments\venv\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

[36mray::ClientAppActor.run()[39m (pid=134984, ip=127.0.0.1, actor_id=b7eeab642151a456c61cda4001000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x0000026D546DF2C0>)
  File "python\ray\_raylet.pyx", line 1890, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 1991, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 1896, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 1837, in ray._raylet.execute_task.function_executor
  File "D:\Research\FL_experiments\venv\Lib\site-packages\ray\_private\function_manager.py", line 691, in actor_method_executor
    return method(__ray_actor, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\ray\util\tracing\tracing_helper.py", line 467, in _resume_span
    return method(self, *_args, **_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Research\FL_experiments\venv\Lib\site-packages\flwr\simulation\ray_transport\ray_actor.py", line 64, in run
    raise ClientAppException(str(ex)) from ex
flwr.client.client_app.ClientAppException: 
Exception ClientAppException occurred. Message: The read operation timed out'>
  â””â”€â”€ Average Train Loss: 2.2396e+00
[Round 1] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 1] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 2.1610, Acc: 0.5344 (53.44%)
----------------------------------------------------------------------
[Round 2] Configure Train: Sampled 100 nodes (out of 100)

[Round 2] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.0529e+00
[Round 2] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 2] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 1.9113, Acc: 0.6628 (66.28%)
----------------------------------------------------------------------
[Round 3] Configure Train: Sampled 100 nodes (out of 100)

[Round 3] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 1.7264e+00
[Round 3] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 3] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 1.5101, Acc: 0.7071 (70.71%)
----------------------------------------------------------------------
[Round 4] Configure Train: Sampled 100 nodes (out of 100)

[Round 4] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 1.3180e+00
[Round 4] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 4] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 1.1241, Acc: 0.7606 (76.06%)
----------------------------------------------------------------------
[Round 5] Configure Train: Sampled 100 nodes (out of 100)

[Round 5] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 1.0029e+00
[Round 5] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 5] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.8760, Acc: 0.7998 (79.98%)
----------------------------------------------------------------------
[Round 6] Configure Train: Sampled 100 nodes (out of 100)

[Round 6] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 8.1122e-01
[Round 6] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 6] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.7282, Acc: 0.8212 (82.12%)
----------------------------------------------------------------------
[Round 7] Configure Train: Sampled 100 nodes (out of 100)

[Round 7] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 6.9433e-01
[Round 7] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 7] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.6348, Acc: 0.8373 (83.73%)
----------------------------------------------------------------------
[Round 8] Configure Train: Sampled 100 nodes (out of 100)

[Round 8] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 6.1692e-01
[Round 8] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 8] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.5702, Acc: 0.8512 (85.12%)
----------------------------------------------------------------------
[Round 9] Configure Train: Sampled 100 nodes (out of 100)

[Round 9] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 5.6139e-01
[Round 9] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 9] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.5240, Acc: 0.8608 (86.08%)
----------------------------------------------------------------------
[Round 10] Configure Train: Sampled 100 nodes (out of 100)

[Round 10] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 5.2117e-01
[Round 10] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 10] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.4886, Acc: 0.8690 (86.90%)
----------------------------------------------------------------------
[Round 11] Configure Train: Sampled 100 nodes (out of 100)

[Round 11] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 4.9016e-01
[Round 11] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 11] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.4612, Acc: 0.8730 (87.30%)
----------------------------------------------------------------------
[Round 12] Configure Train: Sampled 100 nodes (out of 100)

[Round 12] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 4.6614e-01
[Round 12] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 12] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.4392, Acc: 0.8772 (87.72%)
----------------------------------------------------------------------
[Round 13] Configure Train: Sampled 100 nodes (out of 100)

[Round 13] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 4.4461e-01
[Round 13] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 13] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.4213, Acc: 0.8805 (88.05%)
----------------------------------------------------------------------
[Round 14] Configure Train: Sampled 100 nodes (out of 100)

[Round 14] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 4.2860e-01
[Round 14] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 14] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.4065, Acc: 0.8842 (88.42%)
----------------------------------------------------------------------
[Round 15] Configure Train: Sampled 100 nodes (out of 100)

[Round 15] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 4.1427e-01
[Round 15] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 15] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3938, Acc: 0.8876 (88.76%)
----------------------------------------------------------------------
[Round 16] Configure Train: Sampled 100 nodes (out of 100)

[Round 16] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 4.0142e-01
[Round 16] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 16] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3829, Acc: 0.8895 (88.95%)
----------------------------------------------------------------------
[Round 17] Configure Train: Sampled 100 nodes (out of 100)

[Round 17] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.9086e-01
[Round 17] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 17] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3740, Acc: 0.8912 (89.12%)
----------------------------------------------------------------------
[Round 18] Configure Train: Sampled 100 nodes (out of 100)

[Round 18] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.8187e-01
[Round 18] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 18] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3648, Acc: 0.8932 (89.33%)
----------------------------------------------------------------------
[Round 19] Configure Train: Sampled 100 nodes (out of 100)

[Round 19] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.7339e-01
[Round 19] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 19] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3576, Acc: 0.8953 (89.53%)
----------------------------------------------------------------------
[Round 20] Configure Train: Sampled 100 nodes (out of 100)

[Round 20] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.6630e-01
[Round 20] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 20] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3508, Acc: 0.8978 (89.78%)
----------------------------------------------------------------------
[Round 21] Configure Train: Sampled 100 nodes (out of 100)

[Round 21] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.5863e-01
[Round 21] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 21] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3446, Acc: 0.8995 (89.95%)
----------------------------------------------------------------------
[Round 22] Configure Train: Sampled 100 nodes (out of 100)

[Round 22] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.5210e-01
[Round 22] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 22] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3387, Acc: 0.9008 (90.08%)
----------------------------------------------------------------------
[Round 23] Configure Train: Sampled 100 nodes (out of 100)

[Round 23] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.4678e-01
[Round 23] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 23] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3337, Acc: 0.9024 (90.24%)
----------------------------------------------------------------------
[Round 24] Configure Train: Sampled 100 nodes (out of 100)

[Round 24] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.4042e-01
[Round 24] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 24] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3288, Acc: 0.9031 (90.31%)
----------------------------------------------------------------------
[Round 25] Configure Train: Sampled 100 nodes (out of 100)

[Round 25] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.3557e-01
[Round 25] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 25] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3241, Acc: 0.9047 (90.47%)
----------------------------------------------------------------------
[Round 26] Configure Train: Sampled 100 nodes (out of 100)

[Round 26] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.3079e-01
[Round 26] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 26] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3202, Acc: 0.9063 (90.63%)
----------------------------------------------------------------------
[Round 27] Configure Train: Sampled 100 nodes (out of 100)

[Round 27] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.2648e-01
[Round 27] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 27] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3159, Acc: 0.9071 (90.71%)
----------------------------------------------------------------------
[Round 28] Configure Train: Sampled 100 nodes (out of 100)

[Round 28] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.2205e-01
[Round 28] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 28] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3116, Acc: 0.9082 (90.82%)
----------------------------------------------------------------------
[Round 29] Configure Train: Sampled 100 nodes (out of 100)

[Round 29] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.1735e-01
[Round 29] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 29] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3081, Acc: 0.9095 (90.95%)
----------------------------------------------------------------------
[Round 30] Configure Train: Sampled 100 nodes (out of 100)

[Round 30] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.1322e-01
[Round 30] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 30] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3047, Acc: 0.9107 (91.07%)
----------------------------------------------------------------------
[Round 31] Configure Train: Sampled 100 nodes (out of 100)

[Round 31] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.0878e-01
[Round 31] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 31] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.3012, Acc: 0.9119 (91.19%)
----------------------------------------------------------------------
[Round 32] Configure Train: Sampled 100 nodes (out of 100)

[Round 32] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.0527e-01
[Round 32] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 32] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2979, Acc: 0.9122 (91.22%)
----------------------------------------------------------------------
[Round 33] Configure Train: Sampled 100 nodes (out of 100)

[Round 33] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 3.0101e-01
[Round 33] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 33] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2948, Acc: 0.9133 (91.33%)
----------------------------------------------------------------------
[Round 34] Configure Train: Sampled 100 nodes (out of 100)

[Round 34] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.9723e-01
[Round 34] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 34] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2915, Acc: 0.9142 (91.42%)
----------------------------------------------------------------------
[Round 35] Configure Train: Sampled 100 nodes (out of 100)

[Round 35] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.9445e-01
[Round 35] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 35] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2886, Acc: 0.9154 (91.54%)
----------------------------------------------------------------------
[Round 36] Configure Train: Sampled 100 nodes (out of 100)

[Round 36] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.9032e-01
[Round 36] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 36] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2856, Acc: 0.9169 (91.69%)
----------------------------------------------------------------------
[Round 37] Configure Train: Sampled 100 nodes (out of 100)

[Round 37] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.8745e-01
[Round 37] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 37] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2831, Acc: 0.9174 (91.74%)
----------------------------------------------------------------------
[Round 38] Configure Train: Sampled 100 nodes (out of 100)

[Round 38] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.8511e-01
[Round 38] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 38] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2801, Acc: 0.9186 (91.86%)
----------------------------------------------------------------------
[Round 39] Configure Train: Sampled 100 nodes (out of 100)

[Round 39] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.8055e-01
[Round 39] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 39] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2777, Acc: 0.9196 (91.96%)
----------------------------------------------------------------------
[Round 40] Configure Train: Sampled 100 nodes (out of 100)

[Round 40] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.7753e-01
[Round 40] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 40] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2750, Acc: 0.9202 (92.02%)
----------------------------------------------------------------------
[Round 41] Configure Train: Sampled 100 nodes (out of 100)

[Round 41] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.7478e-01
[Round 41] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 41] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2724, Acc: 0.9203 (92.03%)
----------------------------------------------------------------------
[Round 42] Configure Train: Sampled 100 nodes (out of 100)

[Round 42] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.7194e-01
[Round 42] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 42] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2701, Acc: 0.9212 (92.12%)
----------------------------------------------------------------------
[Round 43] Configure Train: Sampled 100 nodes (out of 100)

[Round 43] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.6914e-01
[Round 43] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 43] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2678, Acc: 0.9216 (92.16%)
----------------------------------------------------------------------
[Round 44] Configure Train: Sampled 100 nodes (out of 100)

[Round 44] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.6699e-01
[Round 44] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 44] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2659, Acc: 0.9229 (92.29%)
----------------------------------------------------------------------
[Round 45] Configure Train: Sampled 100 nodes (out of 100)

[Round 45] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.6372e-01
[Round 45] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 45] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2629, Acc: 0.9231 (92.31%)
----------------------------------------------------------------------
[Round 46] Configure Train: Sampled 100 nodes (out of 100)

[Round 46] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.6032e-01
[Round 46] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 46] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2610, Acc: 0.9236 (92.36%)
----------------------------------------------------------------------
[Round 47] Configure Train: Sampled 100 nodes (out of 100)

[Round 47] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.5810e-01
[Round 47] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 47] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2591, Acc: 0.9240 (92.40%)
----------------------------------------------------------------------
[Round 48] Configure Train: Sampled 100 nodes (out of 100)

[Round 48] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.5526e-01
[Round 48] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 48] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2568, Acc: 0.9247 (92.47%)
----------------------------------------------------------------------
[Round 49] Configure Train: Sampled 100 nodes (out of 100)

[Round 49] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.5294e-01
[Round 49] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 49] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2542, Acc: 0.9255 (92.55%)
----------------------------------------------------------------------
[Round 50] Configure Train: Sampled 100 nodes (out of 100)

[Round 50] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.5032e-01
[Round 50] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 50] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2522, Acc: 0.9259 (92.59%)
----------------------------------------------------------------------
[Round 51] Configure Train: Sampled 100 nodes (out of 100)

[Round 51] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.4805e-01
[Round 51] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 51] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2502, Acc: 0.9266 (92.66%)
----------------------------------------------------------------------
[Round 52] Configure Train: Sampled 100 nodes (out of 100)

[Round 52] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.4611e-01
[Round 52] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 52] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2483, Acc: 0.9268 (92.68%)
----------------------------------------------------------------------
[Round 53] Configure Train: Sampled 100 nodes (out of 100)

[Round 53] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.4366e-01
[Round 53] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 53] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2464, Acc: 0.9280 (92.80%)
----------------------------------------------------------------------
[Round 54] Configure Train: Sampled 100 nodes (out of 100)

[Round 54] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.4105e-01
[Round 54] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 54] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2442, Acc: 0.9279 (92.79%)
----------------------------------------------------------------------
[Round 55] Configure Train: Sampled 100 nodes (out of 100)

[Round 55] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.3873e-01
[Round 55] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 55] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2423, Acc: 0.9289 (92.89%)
----------------------------------------------------------------------
[Round 56] Configure Train: Sampled 100 nodes (out of 100)

[Round 56] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.3684e-01
[Round 56] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 56] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2403, Acc: 0.9297 (92.97%)
----------------------------------------------------------------------
[Round 57] Configure Train: Sampled 100 nodes (out of 100)

[Round 57] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.3450e-01
[Round 57] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 57] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2386, Acc: 0.9303 (93.03%)
----------------------------------------------------------------------
[Round 58] Configure Train: Sampled 100 nodes (out of 100)

[Round 58] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.3174e-01
[Round 58] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 58] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2368, Acc: 0.9304 (93.04%)
----------------------------------------------------------------------
[Round 59] Configure Train: Sampled 100 nodes (out of 100)

[Round 59] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.2981e-01
[Round 59] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 59] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2350, Acc: 0.9312 (93.12%)
----------------------------------------------------------------------
[Round 60] Configure Train: Sampled 100 nodes (out of 100)

[Round 60] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.2790e-01
[Round 60] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 60] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2330, Acc: 0.9312 (93.12%)
----------------------------------------------------------------------
[Round 61] Configure Train: Sampled 100 nodes (out of 100)

[Round 61] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.2573e-01
[Round 61] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 61] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2315, Acc: 0.9322 (93.22%)
----------------------------------------------------------------------
[Round 62] Configure Train: Sampled 100 nodes (out of 100)

[Round 62] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.2381e-01
[Round 62] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 62] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2300, Acc: 0.9335 (93.35%)
----------------------------------------------------------------------
[Round 63] Configure Train: Sampled 100 nodes (out of 100)

[Round 63] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.2251e-01
[Round 63] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 63] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2282, Acc: 0.9332 (93.32%)
----------------------------------------------------------------------
[Round 64] Configure Train: Sampled 100 nodes (out of 100)

[Round 64] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.2014e-01
[Round 64] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 64] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2264, Acc: 0.9336 (93.36%)
----------------------------------------------------------------------
[Round 65] Configure Train: Sampled 100 nodes (out of 100)

[Round 65] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.1806e-01
[Round 65] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 65] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2252, Acc: 0.9340 (93.40%)
----------------------------------------------------------------------
[Round 66] Configure Train: Sampled 100 nodes (out of 100)

[Round 66] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.1681e-01
[Round 66] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 66] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2230, Acc: 0.9347 (93.47%)
----------------------------------------------------------------------
[Round 67] Configure Train: Sampled 100 nodes (out of 100)

[Round 67] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.1431e-01
[Round 67] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 67] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2216, Acc: 0.9348 (93.48%)
----------------------------------------------------------------------
[Round 68] Configure Train: Sampled 100 nodes (out of 100)

[Round 68] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.1269e-01
[Round 68] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 68] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2200, Acc: 0.9358 (93.58%)
----------------------------------------------------------------------
[Round 69] Configure Train: Sampled 100 nodes (out of 100)

[Round 69] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.1072e-01
[Round 69] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 69] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2185, Acc: 0.9360 (93.60%)
----------------------------------------------------------------------
[Round 70] Configure Train: Sampled 100 nodes (out of 100)

[Round 70] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.0846e-01
[Round 70] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 70] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2172, Acc: 0.9363 (93.63%)
----------------------------------------------------------------------
[Round 71] Configure Train: Sampled 100 nodes (out of 100)

[Round 71] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.0693e-01
[Round 71] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 71] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2158, Acc: 0.9370 (93.70%)
----------------------------------------------------------------------
[Round 72] Configure Train: Sampled 100 nodes (out of 100)

[Round 72] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.0561e-01
[Round 72] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 72] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2143, Acc: 0.9369 (93.69%)
----------------------------------------------------------------------
[Round 73] Configure Train: Sampled 100 nodes (out of 100)

[Round 73] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.0377e-01
[Round 73] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 73] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2127, Acc: 0.9376 (93.76%)
----------------------------------------------------------------------
[Round 74] Configure Train: Sampled 100 nodes (out of 100)

[Round 74] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.0214e-01
[Round 74] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 74] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2114, Acc: 0.9379 (93.79%)
----------------------------------------------------------------------
[Round 75] Configure Train: Sampled 100 nodes (out of 100)

[Round 75] Aggregate Train:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Average Train Loss: 2.0048e-01
[Round 75] Configure Evaluate: Sampled 100 nodes (out of 100)

[Round 75] Aggregate Evaluate:
  â”œâ”€â”€ Received 100 results and 0 failures
  â””â”€â”€ Loss: 0.2099, Acc: 0.9382 (93.82%)
----------------------------------------------------------------------

======================================================================
EXPERIMENT SUMMARY
======================================================================
End Time: 2025-11-02 19:54:16
Total Duration: 0:13:57.876039
Total Rounds Completed: 75

âœ— Target Accuracy (97%) not reached
  Best accuracy: 0.9382 (93.82%) at round 75

======================================================================
ALL TRAINING METRICS
======================================================================
1: {'train_loss': '2.2396e+00'}
2: {'train_loss': '2.0529e+00'}
3: {'train_loss': '1.7264e+00'}
4: {'train_loss': '1.3180e+00'}
5: {'train_loss': '1.0029e+00'}
6: {'train_loss': '8.1122e-01'}
7: {'train_loss': '6.9433e-01'}
8: {'train_loss': '6.1692e-01'}
9: {'train_loss': '5.6139e-01'}
10: {'train_loss': '5.2117e-01'}
11: {'train_loss': '4.9016e-01'}
12: {'train_loss': '4.6614e-01'}
13: {'train_loss': '4.4461e-01'}
14: {'train_loss': '4.2860e-01'}
15: {'train_loss': '4.1427e-01'}
16: {'train_loss': '4.0142e-01'}
17: {'train_loss': '3.9086e-01'}
18: {'train_loss': '3.8187e-01'}
19: {'train_loss': '3.7339e-01'}
20: {'train_loss': '3.6630e-01'}
21: {'train_loss': '3.5863e-01'}
22: {'train_loss': '3.5210e-01'}
23: {'train_loss': '3.4678e-01'}
24: {'train_loss': '3.4042e-01'}
25: {'train_loss': '3.3557e-01'}
26: {'train_loss': '3.3079e-01'}
27: {'train_loss': '3.2648e-01'}
28: {'train_loss': '3.2205e-01'}
29: {'train_loss': '3.1735e-01'}
30: {'train_loss': '3.1322e-01'}
31: {'train_loss': '3.0878e-01'}
32: {'train_loss': '3.0527e-01'}
33: {'train_loss': '3.0101e-01'}
34: {'train_loss': '2.9723e-01'}
35: {'train_loss': '2.9445e-01'}
36: {'train_loss': '2.9032e-01'}
37: {'train_loss': '2.8745e-01'}
38: {'train_loss': '2.8511e-01'}
39: {'train_loss': '2.8055e-01'}
40: {'train_loss': '2.7753e-01'}
41: {'train_loss': '2.7478e-01'}
42: {'train_loss': '2.7194e-01'}
43: {'train_loss': '2.6914e-01'}
44: {'train_loss': '2.6699e-01'}
45: {'train_loss': '2.6372e-01'}
46: {'train_loss': '2.6032e-01'}
47: {'train_loss': '2.5810e-01'}
48: {'train_loss': '2.5526e-01'}
49: {'train_loss': '2.5294e-01'}
50: {'train_loss': '2.5032e-01'}
51: {'train_loss': '2.4805e-01'}
52: {'train_loss': '2.4611e-01'}
53: {'train_loss': '2.4366e-01'}
54: {'train_loss': '2.4105e-01'}
55: {'train_loss': '2.3873e-01'}
56: {'train_loss': '2.3684e-01'}
57: {'train_loss': '2.3450e-01'}
58: {'train_loss': '2.3174e-01'}
59: {'train_loss': '2.2981e-01'}
60: {'train_loss': '2.2790e-01'}
61: {'train_loss': '2.2573e-01'}
62: {'train_loss': '2.2381e-01'}
63: {'train_loss': '2.2251e-01'}
64: {'train_loss': '2.2014e-01'}
65: {'train_loss': '2.1806e-01'}
66: {'train_loss': '2.1681e-01'}
67: {'train_loss': '2.1431e-01'}
68: {'train_loss': '2.1269e-01'}
69: {'train_loss': '2.1072e-01'}
70: {'train_loss': '2.0846e-01'}
71: {'train_loss': '2.0693e-01'}
72: {'train_loss': '2.0561e-01'}
73: {'train_loss': '2.0377e-01'}
74: {'train_loss': '2.0214e-01'}
75: {'train_loss': '2.0048e-01'}

======================================================================
ALL EVALUATION METRICS
======================================================================
1: {'eval_acc': '5.3442e-01', 'eval_loss': '2.1610e+00'}
2: {'eval_acc': '6.6283e-01', 'eval_loss': '1.9113e+00'}
3: {'eval_acc': '7.0708e-01', 'eval_loss': '1.5101e+00'}
4: {'eval_acc': '7.6058e-01', 'eval_loss': '1.1241e+00'}
5: {'eval_acc': '7.9983e-01', 'eval_loss': '8.7595e-01'}
6: {'eval_acc': '8.2117e-01', 'eval_loss': '7.2824e-01'}
7: {'eval_acc': '8.3733e-01', 'eval_loss': '6.3476e-01'}
8: {'eval_acc': '8.5125e-01', 'eval_loss': '5.7021e-01'}
9: {'eval_acc': '8.6075e-01', 'eval_loss': '5.2402e-01'}
10: {'eval_acc': '8.6900e-01', 'eval_loss': '4.8860e-01'}
11: {'eval_acc': '8.7300e-01', 'eval_loss': '4.6119e-01'}
12: {'eval_acc': '8.7717e-01', 'eval_loss': '4.3921e-01'}
13: {'eval_acc': '8.8050e-01', 'eval_loss': '4.2130e-01'}
14: {'eval_acc': '8.8417e-01', 'eval_loss': '4.0652e-01'}
15: {'eval_acc': '8.8758e-01', 'eval_loss': '3.9383e-01'}
16: {'eval_acc': '8.8950e-01', 'eval_loss': '3.8292e-01'}
17: {'eval_acc': '8.9125e-01', 'eval_loss': '3.7400e-01'}
18: {'eval_acc': '8.9325e-01', 'eval_loss': '3.6485e-01'}
19: {'eval_acc': '8.9525e-01', 'eval_loss': '3.5763e-01'}
20: {'eval_acc': '8.9783e-01', 'eval_loss': '3.5075e-01'}
21: {'eval_acc': '8.9950e-01', 'eval_loss': '3.4458e-01'}
22: {'eval_acc': '9.0075e-01', 'eval_loss': '3.3874e-01'}
23: {'eval_acc': '9.0242e-01', 'eval_loss': '3.3371e-01'}
24: {'eval_acc': '9.0308e-01', 'eval_loss': '3.2878e-01'}
25: {'eval_acc': '9.0475e-01', 'eval_loss': '3.2410e-01'}
26: {'eval_acc': '9.0633e-01', 'eval_loss': '3.2017e-01'}
27: {'eval_acc': '9.0708e-01', 'eval_loss': '3.1594e-01'}
28: {'eval_acc': '9.0817e-01', 'eval_loss': '3.1163e-01'}
29: {'eval_acc': '9.0950e-01', 'eval_loss': '3.0813e-01'}
30: {'eval_acc': '9.1067e-01', 'eval_loss': '3.0470e-01'}
31: {'eval_acc': '9.1192e-01', 'eval_loss': '3.0122e-01'}
32: {'eval_acc': '9.1217e-01', 'eval_loss': '2.9791e-01'}
33: {'eval_acc': '9.1333e-01', 'eval_loss': '2.9484e-01'}
34: {'eval_acc': '9.1417e-01', 'eval_loss': '2.9153e-01'}
35: {'eval_acc': '9.1542e-01', 'eval_loss': '2.8862e-01'}
36: {'eval_acc': '9.1692e-01', 'eval_loss': '2.8563e-01'}
37: {'eval_acc': '9.1742e-01', 'eval_loss': '2.8306e-01'}
38: {'eval_acc': '9.1858e-01', 'eval_loss': '2.8012e-01'}
39: {'eval_acc': '9.1958e-01', 'eval_loss': '2.7775e-01'}
40: {'eval_acc': '9.2017e-01', 'eval_loss': '2.7496e-01'}
41: {'eval_acc': '9.2025e-01', 'eval_loss': '2.7239e-01'}
42: {'eval_acc': '9.2117e-01', 'eval_loss': '2.7010e-01'}
43: {'eval_acc': '9.2158e-01', 'eval_loss': '2.6783e-01'}
44: {'eval_acc': '9.2292e-01', 'eval_loss': '2.6589e-01'}
45: {'eval_acc': '9.2308e-01', 'eval_loss': '2.6293e-01'}
46: {'eval_acc': '9.2358e-01', 'eval_loss': '2.6104e-01'}
47: {'eval_acc': '9.2400e-01', 'eval_loss': '2.5911e-01'}
48: {'eval_acc': '9.2467e-01', 'eval_loss': '2.5677e-01'}
49: {'eval_acc': '9.2550e-01', 'eval_loss': '2.5424e-01'}
50: {'eval_acc': '9.2592e-01', 'eval_loss': '2.5220e-01'}
51: {'eval_acc': '9.2658e-01', 'eval_loss': '2.5020e-01'}
52: {'eval_acc': '9.2683e-01', 'eval_loss': '2.4825e-01'}
53: {'eval_acc': '9.2800e-01', 'eval_loss': '2.4635e-01'}
54: {'eval_acc': '9.2792e-01', 'eval_loss': '2.4420e-01'}
55: {'eval_acc': '9.2892e-01', 'eval_loss': '2.4225e-01'}
56: {'eval_acc': '9.2975e-01', 'eval_loss': '2.4029e-01'}
57: {'eval_acc': '9.3025e-01', 'eval_loss': '2.3863e-01'}
58: {'eval_acc': '9.3042e-01', 'eval_loss': '2.3676e-01'}
59: {'eval_acc': '9.3117e-01', 'eval_loss': '2.3502e-01'}
60: {'eval_acc': '9.3117e-01', 'eval_loss': '2.3297e-01'}
61: {'eval_acc': '9.3225e-01', 'eval_loss': '2.3154e-01'}
62: {'eval_acc': '9.3350e-01', 'eval_loss': '2.3003e-01'}
63: {'eval_acc': '9.3317e-01', 'eval_loss': '2.2824e-01'}
64: {'eval_acc': '9.3358e-01', 'eval_loss': '2.2641e-01'}
65: {'eval_acc': '9.3400e-01', 'eval_loss': '2.2516e-01'}
66: {'eval_acc': '9.3475e-01', 'eval_loss': '2.2304e-01'}
67: {'eval_acc': '9.3483e-01', 'eval_loss': '2.2164e-01'}
68: {'eval_acc': '9.3583e-01', 'eval_loss': '2.2003e-01'}
69: {'eval_acc': '9.3600e-01', 'eval_loss': '2.1852e-01'}
70: {'eval_acc': '9.3633e-01', 'eval_loss': '2.1719e-01'}
71: {'eval_acc': '9.3700e-01', 'eval_loss': '2.1584e-01'}
72: {'eval_acc': '9.3692e-01', 'eval_loss': '2.1426e-01'}
73: {'eval_acc': '9.3758e-01', 'eval_loss': '2.1269e-01'}
74: {'eval_acc': '9.3792e-01', 'eval_loss': '2.1141e-01'}
75: {'eval_acc': '9.3817e-01', 'eval_loss': '2.0987e-01'}

======================================================================
